{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "from importlib import reload\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import OrderedDict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve, accuracy_score\n",
    "\n",
    "# %config InlineBackend.figure_formats = ['svg']\n",
    "# %matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (9, 6)\n",
    "sns.set(context='notebook', style='whitegrid', font_scale=1.2)\n",
    "import matplotlib.cm as cm\n",
    "import random\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import learning_curve\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "import pylab\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "import itertools\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import of cleaned dataset and data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other                         11769\n",
       "Rock                           9452\n",
       "Pop                            6099\n",
       "Blues and Jazz                 4824\n",
       "Rap and Hip Hop                2490\n",
       "Country and Folk               2263\n",
       "Electronic Music and Dance     1580\n",
       "Classical and Opera            1046\n",
       "World Music                     787\n",
       "Reggae and Ska                  250\n",
       "Name: main_parent_genre, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Spotify Data/data-clean.csv')\n",
    "\n",
    "#drop track, artist, track_id \n",
    "df = df.drop(['track', 'artist', 'track_id'], axis=1)\n",
    "\n",
    "df.head(2)\n",
    "df.columns = map(str.lower, df.columns)\n",
    "df['track_seconds'] = df['duration_ms'] / 1000\n",
    "df.columns\n",
    "df.shape\n",
    "\n",
    "#value counts for main_parent_genre\n",
    "df['main_parent_genre'].value_counts()\n",
    "\n",
    "\n",
    "\n",
    "#show which categories are which"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding of genre data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode main_parent_genre\n",
    "df['main_parent_genre'] = df['main_parent_genre'].astype('category')\n",
    "df['main_parent_genre'] = df['main_parent_genre'].cat.codes\n",
    "\n",
    "#df['main_parent_genre'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper function for printing confusion matrices (see: https://gist.github.com/shaypal5/94c53d765083101efc0240d776a23823)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (7,5), fontsize=10):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=(7,5))\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"mako\") #mako\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\n",
    "    plt.ylabel('True label',fontsize=14)\n",
    "    plt.xlabel('Predicted label',fontsize=14)\n",
    "    plt.gcf().subplots_adjust(bottom=0.15)\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(\"xg_confmatrix.png\")\n",
    "    plt.show()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "df = df.drop(columns=['duration_ms', \"popularity\", 'mode', 'key', 'era', 'tiktok', 'spotify', 'popularity'])\n",
    "\n",
    "y = df['target']\n",
    "X = df.drop(columns=['target'])\n",
    "\n",
    "#print(X.info())\n",
    "\n",
    "# Handling missing values\n",
    "imputer = SimpleImputer(strategy='mean')  # Replace missing values with the mean\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "# Print the shape of X to verify the fix\n",
    "# print(X.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot model fucntion based on https://stackoverflow.com/questions/8575062/how-to-show-matplotlib-plots and lecture content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(model, X, y, X2, y2, threshold=0.5):\n",
    "    model.fit(X, y)\n",
    "    y_predict = model.predict(X)\n",
    "    \n",
    "    y_predictprob = (model.predict_proba(X)[:, 1] >= threshold).astype('int')\n",
    "\n",
    "    LR_acc = np.round(np.mean(cross_val_score(model, X, y, scoring='accuracy', cv=5)), 5)\n",
    "    LR_f1 = np.round(np.mean(cross_val_score(model, X, y, scoring='f1', cv=5)), 5)\n",
    "    LR_prec = np.round(np.mean(cross_val_score(model, X, y, scoring='precision', cv=5)), 5)\n",
    "    LR_recall = np.round(np.mean(cross_val_score(model, X, y, scoring='recall', cv=5)), 5)\n",
    "    print(f'The base LR accuracy is: {LR_acc}')\n",
    "    print(f'The base LR f1 is: {LR_f1}')\n",
    "    print(f'The base LR precision is: {LR_prec}')\n",
    "    print(f'The base LR recall is: {LR_recall}')\n",
    "\n",
    "    print(\"Precision: {:6.4f}, Recall: {:6.4f}, Accuracy: {:6.4f}\".format(\n",
    "        precision_score(y, y_predictprob),\n",
    "        recall_score(y, y_predictprob),\n",
    "        accuracy_score(y, y_predictprob)\n",
    "    ))\n",
    "    \n",
    "    m, train_err, test_err = learning_curve(model, X, y, cv=5, scoring='f1', random_state=42)\n",
    "    m_trainerr = np.mean(train_err, axis=1)\n",
    "    m_testerr = np.mean(test_err, axis=1)\n",
    "\n",
    "    print(\"train error\", m_trainerr.mean(), \"test error\", m_testerr.mean())\n",
    "    print(\"y pred proba \", y_predictprob)\n",
    "    \n",
    "    ns2_probs = [0 for _ in range(len(y2))]\n",
    "    y2_predict = model.predict(X2)\n",
    "    y2_predictprobs = model.predict_proba(X2)[:, 1]\n",
    "    y2_predictprob = (model.predict_proba(X2)[:, 1] >= threshold).astype('int')\n",
    "    \n",
    "    print(\"Precision: {:6.4f}, Recall: {:6.4f}, Accuracy: {:6.4f}, f1: {:6.4f}\".format(\n",
    "        precision_score(y2, y2_predictprob),\n",
    "        recall_score(y2, y2_predictprob),\n",
    "        accuracy_score(y2, y2_predictprob),\n",
    "        f1_score(y2, y2_predictprob)\n",
    "    ))\n",
    "    \n",
    "    global y_pred_prob_df\n",
    "    global y_pred_df\n",
    "    y3_predictprob = (model.predict_proba(X2)[:, 1]) \n",
    "    \n",
    "    y_pred_prob_df = pd.DataFrame(y3_predictprob, columns=['y_pred_prob'])\n",
    "    y_pred_df = pd.DataFrame(y2_predictprob, columns=['y_pred'])\n",
    "    \n",
    "    fpr, tpr, thr = roc_curve(y2, y2_predictprobs)\n",
    "    \n",
    "    ns2_auc = roc_auc_score(y2, ns2_probs)\n",
    "    ns2_fpr, ns2_tpr, _ = roc_curve(y2, ns2_probs)\n",
    "\n",
    "    plt.rcParams.update({'figure.figsize': (7, 5)})\n",
    "    \n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('1 - Specificity (FPR)')\n",
    "    plt.ylabel('Sensitivity (TPR)')\n",
    "    plt.title(f\"Area Under the ROC Curve: {np.round(roc_auc_score(y2, y2_predictprobs), 4)}\")\n",
    "\n",
    "    print(f'AUC: {np.round(roc_auc_score(y2, y2_predictprobs), 4)}')\n",
    "\n",
    "    plt.plot(ns2_fpr, ns2_tpr, linestyle='--', label='No Skill')\n",
    "    plt.tight_layout()\n",
    "    plt.show\n",
    "    #plt.savefig(\"xg_aucroc.pdf\")\n",
    "    \n",
    "    conf_mat = confusion_matrix(y2, y2_predictprob)\n",
    "    cm = print_confusion_matrix(conf_mat, ['not a hit', 'is a hit'])\n",
    "    \n",
    "    return y_pred_prob_df, y_pred_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosting is the classifier used in our prediction, after having do a model evaluation and selection (see ml_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The base LR accuracy is: 0.79487\n",
      "The base LR f1 is: 0.79966\n",
      "The base LR precision is: 0.76417\n",
      "The base LR recall is: 0.83559\n",
      "Precision: 0.7719, Recall: 0.8510, Accuracy: 0.8028\n"
     ]
    }
   ],
   "source": [
    "xgb2=GradientBoostingClassifier(                   \n",
    "                   max_depth=3, \n",
    "                   max_features=4,\n",
    "                   max_leaf_nodes=None,                   \n",
    "                   #min_samples_leaf=10,\n",
    "                   n_estimators=100,\n",
    "                   learning_rate=0.1)\n",
    "xgb2b = xgb2.fit(X2_train,y2_train)\n",
    "\n",
    "grad_ypred = xgb2.predict(X2_test)\n",
    "\n",
    "grad_yproba = xgb2.predict_proba(X2_test)[:,1]\n",
    "\n",
    "fpr_grad, tpr_grad, _ = roc_curve(y2_test, grad_yproba)\n",
    "plot_model(xgb2, X2_train, y2_train, X2_test, y2_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle the model for use in other workflow of the web app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# plot_model(xgb2, X3_train, y2_train, X3_test, y2_test)\n",
    "# plot_model(xgb2, X2_train, y2_train, X2_test, y2_test)\n",
    "pickle.dump(xgb2, open('xgb_model_genre.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
