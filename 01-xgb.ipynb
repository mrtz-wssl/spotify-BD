{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pylab inline\n",
    "\n",
    "# sets backend to render higher res images\n",
    "#%matplotlib InlineBackend.figure_formats = ['retina']\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import OrderedDict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve, accuracy_score\n",
    "\n",
    "# %config InlineBackend.figure_formats = ['svg']\n",
    "# %matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (9, 6)\n",
    "sns.set(context='notebook', style='whitegrid', font_scale=1.2)\n",
    "import matplotlib.cm as cm\n",
    "import random\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_signature</th>\n",
       "      <th>chorus_hit</th>\n",
       "      <th>sections</th>\n",
       "      <th>target</th>\n",
       "      <th>popularity</th>\n",
       "      <th>sm_target</th>\n",
       "      <th>tiktok</th>\n",
       "      <th>spotify</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>danceability</th>\n",
       "      <th>...</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>era</th>\n",
       "      <th>main_parent_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>32.94975</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173533.0</td>\n",
       "      <td>0.417</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.727</td>\n",
       "      <td>major</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0779</td>\n",
       "      <td>0.845</td>\n",
       "      <td>185.655</td>\n",
       "      <td>60s</td>\n",
       "      <td>Blues and Jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>48.82510</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>213613.0</td>\n",
       "      <td>0.498</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.475</td>\n",
       "      <td>major</td>\n",
       "      <td>0.0337</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.1760</td>\n",
       "      <td>0.797</td>\n",
       "      <td>101.801</td>\n",
       "      <td>60s</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_signature  chorus_hit  sections  target  popularity  sm_target  \\\n",
       "0             3.0    32.94975       9.0     1.0         NaN        0.0   \n",
       "1             4.0    48.82510      10.0     0.0         NaN        0.0   \n",
       "\n",
       "   tiktok  spotify  duration_ms  danceability  ...  loudness   mode  \\\n",
       "0       0        1     173533.0         0.417  ...    -7.727  major   \n",
       "1       0        1     213613.0         0.498  ...   -12.475  major   \n",
       "\n",
       "   speechiness acousticness  instrumentalness  liveness  valence    tempo  \\\n",
       "0       0.0403        0.490             0.000    0.0779    0.845  185.655   \n",
       "1       0.0337        0.018             0.107    0.1760    0.797  101.801   \n",
       "\n",
       "   era  main_parent_genre  \n",
       "0  60s     Blues and Jazz  \n",
       "1  60s               Rock  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Spotify Data/data-clean.csv')\n",
    "\n",
    "#drop track, artist, track_id \n",
    "df = df.drop(['track', 'artist', 'track_id'], axis=1)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40560, 23)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = map(str.lower, df.columns)\n",
    "df['track_seconds'] = df['duration_ms'] / 1000\n",
    "df.columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import learning_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for printing confusion matrices (see: https://gist.github.com/shaypal5/94c53d765083101efc0240d776a23823)\n",
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (7,5), fontsize=10):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=(7,5))\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"mako\") #mako\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\n",
    "    plt.ylabel('True label',fontsize=14)\n",
    "    plt.xlabel('Predicted label',fontsize=14)\n",
    "    plt.gcf().subplots_adjust(bottom=0.15)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"xg_confmatrix.png\")\n",
    "    plt.show()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40560, 14)\n"
     ]
    }
   ],
   "source": [
    "# Establishing X and y\n",
    "# df = df.drop(columns = ['duration_ms', 'mode', 'key', 'era', 'main_parent_genre', 'sm_target', 'tiktok','spotify'  ])\n",
    "\n",
    "\n",
    "# y = df['target']\n",
    "# X = df.drop(columns = ['target'])\n",
    "\n",
    "# # Train test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "# X2_train, X2_test,  y2_train,y2_test = train_test_split(X_train,y_train, test_size = 0.25, random_state = 42)\n",
    "\n",
    "# #historgram of values of y and show it\n",
    "# X.shape\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "df = df.drop(columns=['duration_ms', 'mode', 'key', 'era', 'main_parent_genre', 'sm_target', 'tiktok', 'spotify'])\n",
    "\n",
    "y = df['target']\n",
    "X = df.drop(columns=['target'])\n",
    "\n",
    "# Handling missing values\n",
    "imputer = SimpleImputer(strategy='mean')  # Replace missing values with the mean\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "# Print the shape of X to verify the fix\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "import pylab\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Function used to plot the learning curve, roc curve, and confusing matrix for the given model\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_model(model, X, y , X2, y2,threshold=0.5):\n",
    "#     model.fit(X, y)\n",
    "#     y_predict = model.predict(X)\n",
    "#     #y_predictprob = model.predict_proba(X)[:, 1]\n",
    "    \n",
    "#     y_predictprob = (model.predict_proba(X)[:, 1] >=threshold).astype('int')\n",
    "\n",
    "#     LR_acc = np.round(np.mean(cross_val_score(model, X, y, scoring = 'accuracy', cv = 5)), 5)\n",
    "#     LR_f1 = np.round(np.mean(cross_val_score(model, X, y, scoring = 'f1', cv = 5)), 5)\n",
    "#     LR_prec = np.round(np.mean(cross_val_score(model, X, y, scoring = 'precision', cv = 5)), 5)\n",
    "#     LR_recall = np.round(np.mean(cross_val_score(model, X, y, scoring = 'recall', cv = 5)), 5)\n",
    "#     print(f'The base LR accuracy is: {LR_acc}')\n",
    "#     print(f'The base LR f1 is: {LR_f1}')\n",
    "#     print(f'The base LR precision is: {LR_prec}')\n",
    "#     print(f'The base LR recall is: {LR_recall}')\n",
    "\n",
    "#     #print(\"train : all metrics:\", metrics.classification_report(y,y_predictprob))\n",
    "\n",
    "#     print(\"Precision: {:6.4f},   Recall: {:6.4f}, Accuracy: {:6.4f}\".format(precision_score(y, y_predictprob),\n",
    "#                                                         recall_score(y, y_predictprob) ,\n",
    "#                                                         accuracy_score(y,y_predictprob)))\n",
    "    \n",
    "    \n",
    "#     m, train_err, test_err = learning_curve(model, X, y, cv = 5, scoring = 'f1', random_state = 42)\n",
    "#     m_trainerr = np.mean(train_err, axis = 1)\n",
    "#     m_testerr = np.mean(test_err, axis = 1)\n",
    "\n",
    "#     print(\"train error\", m_trainerr.mean(), \"test error\", m_testerr.mean())\n",
    "#     print(\"y pred proba \",y_predictprob)\n",
    "    \n",
    "    \n",
    "#     # try\n",
    "    \n",
    "#     ns2_probs = [0 for _ in range(len(y2))]\n",
    "#     y2_predict = model.predict(X2)\n",
    "#     y2_predictprobs = model.predict_proba(X2)[:, 1]\n",
    "#     y2_predictprob = (model.predict_proba(X2)[:, 1]>=threshold).astype('int')\n",
    "    \n",
    "#     #print(\"test : all metrics: \", metrics.classification_report(y2,y2_predictprob))    \n",
    "#     print(\"Precision: {:6.4f},   Recall: {:6.4f}, Accuracy: {:6.4f}, f1: {:6.4f}\".format(precision_score(y2, y2_predictprob),\n",
    "#                                                         recall_score(y2, y2_predictprob) ,\n",
    "#                                                         accuracy_score(y2,y2_predictprob),\n",
    "#                                                         f1_score(y2,y2_predictprob)))\n",
    "    \n",
    "    \n",
    "#     '''\n",
    "#     connect predictions with outputs for sample probablity\n",
    "#     '''\n",
    "#     global y_pred_prob_df \n",
    "#     global y_pred_df\n",
    "#     y3_predictprob = (model.predict_proba(X2)[:, 1]) \n",
    "    \n",
    "# #     print(\"X inputs: \", X2[:10], type(X2))\n",
    "# #     print(\"y predicted prob: \", y3_predictprob[:10], type(y3_predictprob))\n",
    "# #     print(\"y predicted outcomes: \", y2_predictprob[:10], type(y2_predictprob))\n",
    "# #     print(\"y actuals: \",y2[:10] , type(y2))\n",
    "    \n",
    "#     y_pred_prob_df = pd.DataFrame(y3_predictprob,columns=['y_pred_prob'])\n",
    "#     y_pred_df = pd.DataFrame(y2_predictprob,columns=['y_pred'])    \n",
    "    \n",
    "#     '''\n",
    "#     change array and series to df\n",
    "#     '''\n",
    "    \n",
    "#     fpr, tpr, thr = roc_curve(y2, y2_predictprobs)\n",
    "    \n",
    "#     ns2_auc = roc_auc_score(y2, ns2_probs)\n",
    "#     ns2_fpr, ns2_tpr, _ = roc_curve(y2, ns2_probs)\n",
    "\n",
    "# #     optimal_idx = np.argmax(tpr - fpr)\n",
    "# #     optimal_threshold = thresholds[optimal_idx]\n",
    "# #     print(\"optimal idx\", optimal_idx, \"optimal threshold\", optimal_threshold)\n",
    "    \n",
    "#     plt.rcParams.update({'figure.figsize': (7, 5)})\n",
    "# #     plt.subplot(1,2,1)\n",
    "# #     plt.plot(m, m_trainerr, 'k', m, m_testerr, 'r')\n",
    "# #     plt.xlabel('Number of Samples', fontsize = 10)\n",
    "# #     plt.ylabel('F1', fontsize = 10)\n",
    "# #     plt.legend(['Training Error', 'Test Error'])\n",
    "#     #plt.subplot(1,2,2)\n",
    "    \n",
    "#     plt.plot(fpr, tpr)\n",
    "#     plt.xlabel('1 - Specificity (FPR)')\n",
    "#     plt.ylabel('Sensitivity (TPR)');\n",
    "#     plt.title(f\"Area Under the ROC Curve: {np.round(roc_auc_score(y2, y2_predictprobs), 4)}\");\n",
    "\n",
    "#     print(f'AUC: {np.round(roc_auc_score(y2, y2_predictprobs), 4)}')\n",
    "\n",
    "\n",
    "#     pyplot.plot(ns2_fpr, ns2_tpr, linestyle='--', label='No Skill')\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(\"xg_aucroc.pdf\")\n",
    "    \n",
    "    \n",
    "#     conf_mat = confusion_matrix(y2, y2_predictprob)\n",
    "#     cm = print_confusion_matrix(conf_mat, ['not a hit', 'is a hit'])\n",
    "    \n",
    "#     return y_pred_prob_df, y_pred_df\n",
    "\n",
    "def plot_model(model, X, y, X2, y2, threshold=0.5):\n",
    "    model.fit(X, y)\n",
    "    y_predict = model.predict(X)\n",
    "    \n",
    "    y_predictprob = (model.predict_proba(X)[:, 1] >= threshold).astype('int')\n",
    "\n",
    "    LR_acc = np.round(np.mean(cross_val_score(model, X, y, scoring='accuracy', cv=5)), 5)\n",
    "    LR_f1 = np.round(np.mean(cross_val_score(model, X, y, scoring='f1', cv=5)), 5)\n",
    "    LR_prec = np.round(np.mean(cross_val_score(model, X, y, scoring='precision', cv=5)), 5)\n",
    "    LR_recall = np.round(np.mean(cross_val_score(model, X, y, scoring='recall', cv=5)), 5)\n",
    "    print(f'The base LR accuracy is: {LR_acc}')\n",
    "    print(f'The base LR f1 is: {LR_f1}')\n",
    "    print(f'The base LR precision is: {LR_prec}')\n",
    "    print(f'The base LR recall is: {LR_recall}')\n",
    "\n",
    "    print(\"Precision: {:6.4f}, Recall: {:6.4f}, Accuracy: {:6.4f}\".format(\n",
    "        precision_score(y, y_predictprob),\n",
    "        recall_score(y, y_predictprob),\n",
    "        accuracy_score(y, y_predictprob)\n",
    "    ))\n",
    "    \n",
    "    m, train_err, test_err = learning_curve(model, X, y, cv=5, scoring='f1', random_state=42)\n",
    "    m_trainerr = np.mean(train_err, axis=1)\n",
    "    m_testerr = np.mean(test_err, axis=1)\n",
    "\n",
    "    print(\"train error\", m_trainerr.mean(), \"test error\", m_testerr.mean())\n",
    "    print(\"y pred proba \", y_predictprob)\n",
    "    \n",
    "    ns2_probs = [0 for _ in range(len(y2))]\n",
    "    y2_predict = model.predict(X2)\n",
    "    y2_predictprobs = model.predict_proba(X2)[:, 1]\n",
    "    y2_predictprob = (model.predict_proba(X2)[:, 1] >= threshold).astype('int')\n",
    "    \n",
    "    print(\"Precision: {:6.4f}, Recall: {:6.4f}, Accuracy: {:6.4f}, f1: {:6.4f}\".format(\n",
    "        precision_score(y2, y2_predictprob),\n",
    "        recall_score(y2, y2_predictprob),\n",
    "        accuracy_score(y2, y2_predictprob),\n",
    "        f1_score(y2, y2_predictprob)\n",
    "    ))\n",
    "    \n",
    "    global y_pred_prob_df\n",
    "    global y_pred_df\n",
    "    y3_predictprob = (model.predict_proba(X2)[:, 1]) \n",
    "    \n",
    "    y_pred_prob_df = pd.DataFrame(y3_predictprob, columns=['y_pred_prob'])\n",
    "    y_pred_df = pd.DataFrame(y2_predictprob, columns=['y_pred'])\n",
    "    \n",
    "    fpr, tpr, thr = roc_curve(y2, y2_predictprobs)\n",
    "    \n",
    "    ns2_auc = roc_auc_score(y2, ns2_probs)\n",
    "    ns2_fpr, ns2_tpr, _ = roc_curve(y2, ns2_probs)\n",
    "\n",
    "    plt.rcParams.update({'figure.figsize': (7, 5)})\n",
    "    \n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('1 - Specificity (FPR)')\n",
    "    plt.ylabel('Sensitivity (TPR)')\n",
    "    plt.title(f\"Area Under the ROC Curve: {np.round(roc_auc_score(y2, y2_predictprobs), 4)}\")\n",
    "\n",
    "    print(f'AUC: {np.round(roc_auc_score(y2, y2_predictprobs), 4)}')\n",
    "\n",
    "    plt.plot(ns2_fpr, ns2_tpr, linestyle='--', label='No Skill')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"xg_aucroc.pdf\")\n",
    "    \n",
    "    conf_mat = confusion_matrix(y2, y2_predictprob)\n",
    "    cm = print_confusion_matrix(conf_mat, ['not a hit', 'is a hit'])\n",
    "    \n",
    "    return y_pred_prob_df, y_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The base LR accuracy is: 0.76952\n",
      "The base LR f1 is: 0.78239\n",
      "The base LR precision is: 0.73138\n",
      "The base LR recall is: 0.84118\n",
      "Precision: 0.7388, Recall: 0.8502, Accuracy: 0.7781\n",
      "train error 0.8089718602501568 test error 0.7781758887620205\n",
      "y pred proba  [1 0 0 ... 1 0 0]\n",
      "Precision: 0.7463, Recall: 0.8475, Accuracy: 0.7813, f1: 0.7937\n",
      "AUC: 0.8591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(      y_pred_prob\n",
       " 0        0.411008\n",
       " 1        0.592546\n",
       " 2        0.550659\n",
       " 3        0.033943\n",
       " 4        0.587934\n",
       " ...           ...\n",
       " 8107     0.705847\n",
       " 8108     0.040766\n",
       " 8109     0.720069\n",
       " 8110     0.020291\n",
       " 8111     0.804120\n",
       " \n",
       " [8112 rows x 1 columns],\n",
       "       y_pred\n",
       " 0          0\n",
       " 1          1\n",
       " 2          1\n",
       " 3          0\n",
       " 4          1\n",
       " ...      ...\n",
       " 8107       1\n",
       " 8108       0\n",
       " 8109       1\n",
       " 8110       0\n",
       " 8111       1\n",
       " \n",
       " [8112 rows x 1 columns])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_base = GradientBoostingClassifier()\n",
    "plot_model(xgb_base, X2_train, y2_train, X2_test, y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV For Gradient Boosting\n",
    "grad = GradientBoostingClassifier()\n",
    "grad_param = {'n_estimators':[100],\n",
    "              'max_depth':[3,5],\n",
    "              #'max_features': [6,10],\n",
    "              #'min_samples_split': [None], \n",
    "              #'min_samples_leaf':[3,10],\n",
    "              'learning_rate': [0.1] #0.0001, 0.001, 0.01, \n",
    "             }\n",
    "\n",
    "grad_grid = GridSearchCV(grad, param_grid=grad_param, cv=3, scoring='f1', verbose=True, n_jobs=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "best score:  0.7863362999252607\n",
      "best params:  {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "xgb1 = grad_grid.fit(X2_train,y2_train)\n",
    "\n",
    "grad_ypred = grad_grid.predict(X2_test)\n",
    "\n",
    "grad_yproba = grad_grid.predict_proba(X2_test)[:,1]\n",
    "\n",
    "fpr_grad, tpr_grad, _ = roc_curve(y2_test, grad_yproba)\n",
    "\n",
    "print('best score: ',xgb1.best_score_)\n",
    "print('best params: ',xgb1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb2=GradientBoostingClassifier(                   \n",
    "                   max_depth=3, \n",
    "                   max_features=4,\n",
    "                   max_leaf_nodes=None,                   \n",
    "                   #min_samples_leaf=10,\n",
    "                   n_estimators=100,\n",
    "                   learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb2b = xgb2.fit(X2_train,y2_train)\n",
    "\n",
    "grad_ypred = xgb2.predict(X2_test)\n",
    "\n",
    "grad_yproba = xgb2.predict_proba(X2_test)[:,1]\n",
    "\n",
    "fpr_grad, tpr_grad, _ = roc_curve(y2_test, grad_yproba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The base LR accuracy is: 0.768\n",
      "The base LR f1 is: 0.78038\n",
      "The base LR precision is: 0.72987\n",
      "The base LR recall is: 0.83725\n",
      "Precision: 0.7375, Recall: 0.8480, Accuracy: 0.7765\n",
      "train error 0.8056656053968807 test error 0.778181506450843\n",
      "y pred proba  [1 0 0 ... 1 0 1]\n",
      "Precision: 0.7460, Recall: 0.8428, Accuracy: 0.7796, f1: 0.7915\n",
      "AUC: 0.8568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(      y_pred_prob\n",
       " 0        0.472674\n",
       " 1        0.615463\n",
       " 2        0.543686\n",
       " 3        0.050795\n",
       " 4        0.639391\n",
       " ...           ...\n",
       " 8107     0.664743\n",
       " 8108     0.038510\n",
       " 8109     0.747892\n",
       " 8110     0.037222\n",
       " 8111     0.778468\n",
       " \n",
       " [8112 rows x 1 columns],\n",
       "       y_pred\n",
       " 0          0\n",
       " 1          1\n",
       " 2          1\n",
       " 3          0\n",
       " 4          1\n",
       " ...      ...\n",
       " 8107       1\n",
       " 8108       0\n",
       " 8109       1\n",
       " 8110       0\n",
       " 8111       1\n",
       " \n",
       " [8112 rows x 1 columns])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(xgb2, X2_train, y2_train, X2_test, y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "\n",
    "def plot_variable_importance_top10(model, X_train, top_n=10):\n",
    "    from pandas import DataFrame\n",
    "    imp = DataFrame({\"imp\": model.feature_importances_, \"names\": X_train.columns}).sort_values(\"imp\", ascending=True)\n",
    "    imp_top_n = imp[-top_n:]\n",
    "    fig, ax = plt.subplots(figsize=(imp_top_n.shape[0]/6, imp_top_n.shape[0]/5), dpi=300) \n",
    "    ax.barh(imp_top_n[\"names\"], imp_top_n[\"imp\"], color=\"green\") \n",
    "   # ax.set_xlabel('\\nVariable Importance')\n",
    "   # ax.set_ylabel('Features\\n') \n",
    "    ax.set_title('Variable Importance Plot Top 10\\n') \n",
    "    plt.show()\n",
    "\n",
    "import numpy as np\n",
    "matplotlib.use('TkAgg')  # Set the backend to a GUI-compatible backend\n",
    "\n",
    "\n",
    "# def plot_variable_importance(model, feature_names, top_n=10):\n",
    "#     # Get feature importances from the model\n",
    "#     feature_importances = model.feature_importances_\n",
    "\n",
    "#     # Get the indices of the top N features based on their importance\n",
    "#     top_n_indices = np.argsort(feature_importances)[-top_n:]\n",
    "\n",
    "#     # Get the names of the top N features\n",
    "#     top_n_features = feature_names[top_n_indices]\n",
    "\n",
    "#     # Get the importance values of the top N features\n",
    "#     top_n_importances = feature_importances[top_n_indices]\n",
    "\n",
    "#     # Plotting the variable importance plot\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.barh(range(len(top_n_features)), top_n_importances, align='center')\n",
    "#     plt.yticks(range(len(top_n_features)), top_n_features)\n",
    "#     plt.xlabel('Importance')\n",
    "#     plt.ylabel('Features')\n",
    "#     plt.title(f'Top {top_n} Variable Importance')\n",
    "\n",
    "#     plt.show()  # Display the figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_variable_importance_top10(xgb2, X2_train, top_n=10)\n",
    "\n",
    "# plot_variable_importance_top10(xgb2, X2_train, top_n=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REFITTING BASED ON DROPPED COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X3_train = X2_train.drop(['tempo','speechiness','energy', 'sections'], axis = 1) #mode, key to be dropped here\n",
    "# X3_test = X2_test.drop(['tempo','speechiness','energy', 'sections'], axis = 1)\n",
    "# rlr_secondf1 = plot_model(lr, lr_Xtrain, y2_train, X2_test, y2_test)\n",
    "\n",
    "#column_names wiht all column from X2_train\n",
    "# column_names = ['acousticness', 'danceability', 'duration_ms', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence', 'sections', 'target', 'mode', 'key', 'era', 'main_parent_genre', 'sm_target', 'tiktok', 'spotify', 'track_seconds']\n",
    "column_names = ['time_signature','chorus_hit','sections','danceability','energy','key','loudness','mode','speechiness','acousticness','instrumentalness','liveness','valence','tempo']\n",
    "\n",
    "df_train = pd.DataFrame(X2_train, columns=column_names)\n",
    "df_test = pd.DataFrame(X2_test, columns=column_names)\n",
    "\n",
    "\n",
    "# Drop the specified columns from the DataFrame\n",
    "X3_train = df_train.drop(['tempo', 'speechiness', 'energy', 'sections'], axis=1)\n",
    "X3_test = df_test.drop(['tempo', 'speechiness', 'energy', 'sections'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The base LR accuracy is: 0.74778\n",
      "The base LR f1 is: 0.76326\n",
      "The base LR precision is: 0.7054\n",
      "The base LR recall is: 0.837\n",
      "Precision: 0.7118, Recall: 0.8462, Accuracy: 0.7554\n",
      "train error 0.7860184513277578 test error 0.75999724128998\n",
      "y pred proba  [1 0 0 ... 1 0 0]\n",
      "Precision: 0.7174, Recall: 0.8385, Accuracy: 0.7559, f1: 0.7732\n",
      "AUC: 0.83\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "plot_model(xgb2, X3_train, y2_train, X3_test, y2_test)\n",
    "pickle.dump(xgb2, open('xgb_model.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 14 features, but GradientBoostingClassifier is expecting 10 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m xgb_model_loaded \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mxgb_model.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m \u001b[39mprint\u001b[39m(xgb_model_loaded\u001b[39m.\u001b[39;49mpredict(X_test))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:1308\u001b[0m, in \u001b[0;36mGradientBoostingClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m   1294\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Predict class for X.\u001b[39;00m\n\u001b[1;32m   1295\u001b[0m \n\u001b[1;32m   1296\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1306\u001b[0m \u001b[39m        The predicted values.\u001b[39;00m\n\u001b[1;32m   1307\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1308\u001b[0m     raw_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecision_function(X)\n\u001b[1;32m   1309\u001b[0m     encoded_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_loss\u001b[39m.\u001b[39m_raw_prediction_to_decision(raw_predictions)\n\u001b[1;32m   1310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(encoded_labels, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:1261\u001b[0m, in \u001b[0;36mGradientBoostingClassifier.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecision_function\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m   1243\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the decision function of ``X``.\u001b[39;00m\n\u001b[1;32m   1244\u001b[0m \n\u001b[1;32m   1245\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1259\u001b[0m \u001b[39m        array of shape (n_samples,).\u001b[39;00m\n\u001b[1;32m   1260\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1261\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m   1262\u001b[0m         X, dtype\u001b[39m=\u001b[39;49mDTYPE, order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m   1263\u001b[0m     )\n\u001b[1;32m   1264\u001b[0m     raw_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raw_predict(X)\n\u001b[1;32m   1265\u001b[0m     \u001b[39mif\u001b[39;00m raw_predictions\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 588\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    590\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 389\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    390\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    392\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 14 features, but GradientBoostingClassifier is expecting 10 features as input."
     ]
    }
   ],
   "source": [
    "xgb_model_loaded = pickle.load(open('xgb_model.pkl', 'rb'))\n",
    "print(xgb_model_loaded.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "plot_model(xgb2, X3_train, y2_train, X3_test, y2_test, 0.66) # changing threshold to 0.66 for more precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Create DF for predicted prob/outcomes and merge back to orig df\n",
    "y_pred_prob_df['row_num']= np.arange(len(y_pred_prob_df))\n",
    "\n",
    "y_pred_df['row_num']= np.arange(len(y_pred_df))\n",
    "X_test['row_num']= np.arange(len(X_test))\n",
    "y_test_df = y_test.to_frame()\n",
    "y_test_df['m_index'] = y_test_df.index\n",
    "#y_test_df2=y_test_df.rename_axis('m_index')\n",
    "y_test_df['row_num']= np.arange(len(y_test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "data_frames=[X_test,y_test_df,y_pred_df,y_pred_prob_df]\n",
    "m_results = reduce(lambda left,right: pd.merge(left,right,on=['row_num'], how='outer'),data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "m_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df['m_index'] = df.index\n",
    "final_df = pd.merge(df,m_results,left_on='m_index',right_on='m_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "final_df.to_csv(r'sb_final_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "hit_predict = xgb2.predict(X3_test) #not sure if X3_test is correct\n",
    "hit_score = xgb2.predict_proba(X3_test) #not sure if X3_test is correct\n",
    "print(f'prediction: {hit_predict[0]} \\nprobability of yay: {hit_score[0][1]}\\nprobability of nay: {hit_score[0][0]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
