{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41106 entries, 0 to 41105\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   danceability      41106 non-null  float64\n",
      " 1   energy            41106 non-null  float64\n",
      " 2   key               41106 non-null  float64\n",
      " 3   loudness          41106 non-null  float64\n",
      " 4   mode              41106 non-null  int64  \n",
      " 5   speechiness       41106 non-null  float64\n",
      " 6   acousticness      41106 non-null  float64\n",
      " 7   instrumentalness  41106 non-null  float64\n",
      " 8   liveness          41106 non-null  float64\n",
      " 9   valence           41106 non-null  float64\n",
      " 10  tempo             41106 non-null  float64\n",
      " 11  duration_ms       41106 non-null  float64\n",
      " 12  time_signature    41106 non-null  float64\n",
      " 13  chorus_hit        41106 non-null  float64\n",
      " 14  sections          41106 non-null  float64\n",
      "dtypes: float64(14), int64(1)\n",
      "memory usage: 4.7 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import pylab\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Quickly plot ROC Curve and calculate AUC score for several algorithms to determine the best model\n",
    "\n",
    "df = pd.read_csv('Spotify Data/decaded-combined.csv')\n",
    "\n",
    "data2 = df.copy()\n",
    "data2.loudness = (data2.loudness +50)/max(data2.loudness +50)\n",
    "data2.duration_ms = (data2.duration_ms / 1000)/max(data2.duration_ms / 1000)\n",
    "data2.key = (data2.key)/max(data2.key)\n",
    "data2.tempo = (data2.tempo)/max(data2.tempo)\n",
    "data2.time_signature = (data2.time_signature)/max(data2.time_signature)\n",
    "data2.chorus_hit = (data2.chorus_hit)/max(data2.chorus_hit)\n",
    "data2.sections = (data2.sections)/max(data2.sections)\n",
    "\n",
    "# Establishing X and y\n",
    "y = data2['target']\n",
    "X = data2.drop(columns = ['uri','track', 'artist', 'target'])\n",
    "\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "X2_train, X2_test,  y2_train,y2_test = train_test_split(X_train,y_train, test_size = 0.25, random_state = 42)\n",
    "\n",
    "\n",
    "y.shape\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X2_train, y2_train)\n",
    "knn_ypred = knn.predict(X2_test)\n",
    "knn_proba = knn.predict_proba(X2_test)[:,1]\n",
    "fpr_knn, tpr_knn, _ = roc_curve(y2_test, knn_proba)\n",
    "knn_auc = auc(fpr_knn, tpr_knn)\n",
    "knn_f1 = f1_score(y2_test, knn_ypred)\n",
    "knn_prec = precision_score(y2_test, knn_ypred)\n",
    "knn_recall = recall_score(y2_test, knn_ypred)\n",
    "knn_accuracy = accuracy_score(y2_test, knn_ypred)\n",
    "\n",
    "#LR\n",
    "lr = LogisticRegression(C = 0.5 )\n",
    "lr.fit(X2_train,y2_train)\n",
    "lr_ypred = lr.predict(X2_test)\n",
    "lr_proba = lr.predict_proba(X2_test)[:,1]\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y2_test, lr_proba)\n",
    "lr_auc = auc(fpr_lr, tpr_lr)\n",
    "lr_f1 = f1_score(y2_test, lr_ypred)\n",
    "lr_prec = precision_score(y2_test, lr_ypred)\n",
    "lr_recall = recall_score(y2_test, lr_ypred)\n",
    "lr_accuracy = accuracy_score(y2_test, lr_ypred)\n",
    "\n",
    "# Decision Tree\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X2_train, y2_train)\n",
    "tree_ypred = tree.predict(X2_test)\n",
    "tree_proba = tree.predict_proba(X2_test)[:,1]\n",
    "fpr_tree, tpr_tree, _ = roc_curve(y2_test, tree_proba)\n",
    "tree_auc = auc(fpr_tree, tpr_tree)\n",
    "tree_f1 = f1_score(y2_test, tree_ypred)\n",
    "tree_prec = precision_score(y2_test, tree_ypred)\n",
    "tree_recall = recall_score(y2_test, tree_ypred)\n",
    "tree_accuracy = accuracy_score(y2_test, tree_ypred)\n",
    "\n",
    "\n",
    "# Random Forest\n",
    "forest = RandomForestClassifier(n_estimators=100, max_features=10)\n",
    "forest.fit(X2_train, y2_train)\n",
    "forest_ypred = forest.predict(X2_test)\n",
    "forest_proba = forest.predict_proba(X2_test)[:,1]\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y2_test, forest_proba)\n",
    "forest_auc = auc(fpr_rf, tpr_rf)\n",
    "forest_f1 = f1_score(y2_test, forest_ypred)\n",
    "forest_prec = precision_score(y2_test, forest_ypred)\n",
    "forest_recall = recall_score(y2_test, forest_ypred)\n",
    "forest_accuracy = accuracy_score(y2_test, forest_ypred)\n",
    "\n",
    "# Gradient Boosting\n",
    "grad = GradientBoostingClassifier()\n",
    "grad.fit(X2_train, y2_train)\n",
    "grad_ypred = grad.predict(X2_test)\n",
    "grad_proba = grad.predict_proba(X2_test)[:,1]\n",
    "fpr_gb, tpr_gb, _ = roc_curve(y2_test, grad_proba)\n",
    "grad_auc = auc(fpr_gb, tpr_gb)\n",
    "grad_f1 = f1_score(y2_test, grad_ypred)\n",
    "grad_prec = precision_score(y2_test, grad_ypred)\n",
    "grad_recall = recall_score(y2_test, grad_ypred)\n",
    "grad_accuracy = accuracy_score(y2_test, grad_ypred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision SCORES \n",
      " KNN: 0.7000635458589282 \n",
      " LR: 0.7007268951194184 \n",
      " TREE: 0.7053483807654564 \n",
      " FOREST: 0.7658623771224308 \n",
      " GRAD: 0.7484049340706083\n",
      "Recall SCORES \n",
      " KNN: 0.798502053636144 \n",
      " LR: 0.8151727470403479 \n",
      " TREE: 0.6946122251751631 \n",
      " FOREST: 0.8282193766610292 \n",
      " GRAD: 0.8502053636143996\n",
      "F1 SCORES \n",
      " KNN: 0.7460496613995485 \n",
      " LR: 0.7536296627205717 \n",
      " TREE: 0.699939135727328 \n",
      " FOREST: 0.795821242019733 \n",
      " GRAD: 0.7960637936884968\n",
      "ACCURACY SCORES \n",
      " KNN: 0.7263106678019705 \n",
      " LR: 0.731662814742732 \n",
      " TREE: 0.7001581316141589 \n",
      " FOREST: 0.7860357620727405 \n",
      " GRAD: 0.780683615131979\n",
      "AUC SCORES \n",
      " KNN: 0.780401325852164 \n",
      " LR: 0.8056421044357759 \n",
      " TREE: 0.7004152254951319 \n",
      " FOREST: 0.8614102195165808 \n",
      " GRAD: 0.8576360556880637\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('Precision SCORES',\n",
    "'\\n',\n",
    "'KNN:',knn_prec,\n",
    "'\\n',\n",
    "'LR:', lr_prec,\n",
    "'\\n',\n",
    "'TREE:',tree_prec,\n",
    "'\\n',\n",
    "'FOREST:',forest_prec,\n",
    "'\\n',\n",
    "'GRAD:',grad_prec)\n",
    "\n",
    "print('Recall SCORES',\n",
    "'\\n',\n",
    "'KNN:',knn_recall,\n",
    "'\\n',\n",
    "'LR:', lr_recall,\n",
    "'\\n',\n",
    "'TREE:',tree_recall,\n",
    "'\\n',\n",
    "'FOREST:',forest_recall,\n",
    "'\\n',\n",
    "'GRAD:',grad_recall)\n",
    "\n",
    "\n",
    "print('F1 SCORES',\n",
    "'\\n',\n",
    "'KNN:',knn_f1,\n",
    "'\\n',\n",
    "'LR:', lr_f1,\n",
    "'\\n',\n",
    "'TREE:',tree_f1,\n",
    "'\\n',\n",
    "'FOREST:',forest_f1,\n",
    "'\\n',\n",
    "'GRAD:',grad_f1)\n",
    "\n",
    "print('ACCURACY SCORES',\n",
    "'\\n',\n",
    "'KNN:',knn_accuracy,\n",
    "'\\n',\n",
    "'LR:', lr_accuracy,\n",
    "'\\n',\n",
    "'TREE:',tree_accuracy,\n",
    "'\\n',\n",
    "'FOREST:',forest_accuracy,\n",
    "'\\n',\n",
    "'GRAD:',grad_accuracy)\n",
    "\n",
    "print('AUC SCORES',\n",
    "'\\n',\n",
    "'KNN:',knn_auc,\n",
    "'\\n',\n",
    "'LR:',lr_auc,\n",
    "'\\n',\n",
    "'TREE:',tree_auc,\n",
    "'\\n',\n",
    "'FOREST:',forest_auc,\n",
    "'\\n',\n",
    "'GRAD:',grad_auc)\n",
    "\n",
    "\n",
    "# Gradient Boosting seems to work significantly better, so we'll tune the model using Gradient Boosting going forward\n",
    "\n",
    "pylab.figure(figsize=(10,10))\n",
    "pylab.plot(fpr_knn, tpr_knn, label='knn')\n",
    "pylab.plot(fpr_lr, tpr_lr, label='lr')\n",
    "pylab.plot(fpr_tree, tpr_tree, label='decision tree')\n",
    "pylab.plot(fpr_rf, tpr_rf, label='random forest')\n",
    "pylab.plot(fpr_gb, tpr_gb, label='gradient boosting')\n",
    "pylab.plot([0,1],[0,1], linestyle='dashed')\n",
    "pylab.xlabel('FPR', labelpad=10)\n",
    "pylab.ylabel('TPR',rotation=0, labelpad=15)\n",
    "pylab.legend(loc='upper left')\n",
    "pylab.title('ROC Curves')\n",
    "pylab.savefig('all_aucroc.png')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
